{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"custom_net_skip.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8PTqRjyk42Am"},"source":["Recreation of https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"]},{"cell_type":"code","metadata":{"id":"WTPDU6W34yze","executionInfo":{"status":"ok","timestamp":1619047599500,"user_tz":240,"elapsed":4620,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}}},"source":["import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch import save\n","from torch import load\n","from os import path\n","\n","#import torch.utils.tensorboard as tb\n","\n","from PIL import Image\n","\n","from torchvision import datasets, models, transforms\n","from torch.utils.data import Dataset, DataLoader\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np \n","import random \n","import os, math\n","\n","import gc\n","\n","import pdb\n","from skimage import io \n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","# device = torch.device(\"cpu\")"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f2iSYk7bApXh"},"source":["Reproducibility"]},{"cell_type":"code","metadata":{"id":"P4ym2s_AAoyp","executionInfo":{"status":"ok","timestamp":1619047599502,"user_tz":240,"elapsed":4616,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}}},"source":["# Set manual seed.\n","def runRamdomSeed():\n","    torch.manual_seed(234)\n","    np.random.seed(234)\n","    random.seed(234)\n","    # Disabling the benchmarking feature with torch.backends.cudnn.benchmark = False \n","    # causes cuDNN to deterministically select an algorithm, possibly at the cost of reduced performance.\n","    torch.backends.cudnn.benchmark = False \n","\n","runRamdomSeed()"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JAltxzDh5DLG"},"source":["First we need to import our data."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YvMhA5-2AHLg","executionInfo":{"status":"ok","timestamp":1619047627668,"user_tz":240,"elapsed":32777,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}},"outputId":"08647032-cc75-4319-9095-e1c59f7ef6a9"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5ZBiWNaQD3S2"},"source":["Then we need to establish how we will transform the data to fit into NN"]},{"cell_type":"code","metadata":{"id":"iiRf9KiYD632","executionInfo":{"status":"ok","timestamp":1619047627669,"user_tz":240,"elapsed":32773,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}}},"source":["unused_data_transforms = transforms.Compose([\n","        # transforms.RandomResizedCrop(224),\n","        # transforms.RandomHorizontalFlip(),\n","        transforms.Resize(256),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        ])"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"SG8TTC9W5Bvf","executionInfo":{"status":"ok","timestamp":1619047627669,"user_tz":240,"elapsed":32770,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}}},"source":["\n","class OurDataset(Dataset):\n","    def __init__(self, data_transforms=None, valid=False):\n","        self.data_transforms = data_transforms\n","        if not valid:\n","          csv_path = \"/content/drive/Shareddrives/GeoTracking_AI/image_data.csv\"\n","          self.image_path = \"/content/drive/Shareddrives/GeoTracking_AI/images\"\n","        if valid:\n","          csv_path = \"/content/drive/Shareddrives/GeoTracking_AI/image_valid_data.csv\"\n","          self.image_path = \"/content/drive/Shareddrives/GeoTracking_AI/valid_images\"\n","        \n","        full_csv_frame = pd.read_csv(csv_path)\n","        csv_frame = full_csv_frame[[\"img_id\", \"city_id\", \"heading\"]]\n","        \n","        self.pd_frame = csv_frame\n","\n","        np_frame = csv_frame.to_numpy()\n","\n","        \n","\n","    def __len__(self):\n","        return self.pd_frame.iloc[:, 0].size\n","\n","\n","    def __getitem__(self, idx):\n","        image_path = self.image_path + \"/\" + str(self.pd_frame.iloc[idx, 0]).zfill(5) \n","        img1 = Image.open(image_path + \"_\" + str( (self.pd_frame.iloc[idx, 2]) ).zfill(3) + \".jpg\")\n","        img2 = Image.open(image_path + \"_\" + str( (self.pd_frame.iloc[idx, 2] + 120)%360 ).zfill(3) + \".jpg\")\n","        img3 = Image.open(image_path + \"_\" + str( (self.pd_frame.iloc[idx, 2] + 240)%360 ).zfill(3) + \".jpg\")\n","      \n","        img1 = torch.from_numpy(np.asarray(img1))     # convert to PyTorch Tensor\n","        img2 = torch.from_numpy(np.asarray(img2))  \n","        img3 = torch.from_numpy(np.asarray(img3)) \n","\n","\n","        if self.data_transforms != None:\n","          img1 = self.data_transforms(img1)\n","          img2 = self.data_transforms(img2)\n","          img3 = self.data_transforms(img3)\n","        else:\n","          # Change from 640, 640, 3 to 3, 640, 640\n","          img1 = np.asarray(img1).transpose(-1, 0, 1)\n","          img2 = np.asarray(img2).transpose(-1, 0, 1)\n","          img3 = np.asarray(img3).transpose(-1, 0, 1)\n","        \n","        # img1 = torch.from_numpy(np.asarray(img1))     # convert to PyTorch Tensor (covered in transforms?)\n","        # img2 = torch.from_numpy(np.asarray(img2))     \n","        # img3 = torch.from_numpy(np.asarray(img3))     \n","\n","\n","        return (img1, img2, img3) , self.pd_frame.iloc[idx, 1]\n"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"berUZDtM66Oi"},"source":["Set Arguments"]},{"cell_type":"code","metadata":{"id":"_1YRGXOe67mA","executionInfo":{"status":"ok","timestamp":1619050732250,"user_tz":240,"elapsed":287,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}}},"source":["class Args(object):\n","    pass\n","\n","args = Args();\n","\n","args.learning_rate = .001\n","args.max_epochs = 3\n","args.batch_size = 64\n"],"execution_count":84,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vYdYL7CL49Wj"},"source":["Start by grabbing the already existing ResNet18 library"]},{"cell_type":"code","metadata":{"id":"vLB1ob5T5AKD","executionInfo":{"status":"ok","timestamp":1619051024900,"user_tz":240,"elapsed":629,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}}},"source":["def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n","                 base_width=64, dilation=1):\n","        super(BasicBlock, self).__init__()\n","        if groups != 1 or base_width != 64:\n","            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n","        if dilation > 1:\n","            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n","        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","class Model(nn.Module):\n","  def __init__(self):\n","      super(Model, self).__init__()\n","      self.conv0 = nn.Conv2d(3, 8, 3)\n","      self.conv1 = BasicBlock(8, 8)\n","      self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","      self.conv2 = BasicBlock(8, 8)\n","      self.conv3 = BasicBlock(8, 8)\n","      self.conv4 = BasicBlock(8, 8)\n","      self.conv5 = BasicBlock(8, 8)\n","      self.fc1 = nn.Linear(2888, 120)\n","      self.fc2 = nn.Linear(120, 84)\n","      self.fc3 = nn.Linear(84, 10)            # Note that output has dimension 10\n","  \n","  def forward(self, x):\n","      x = self.pool(F.relu(self.conv0(x)))\n","      x = self.pool(F.relu(self.conv1(x)))\n","      x = self.pool(F.relu(self.conv2(x)))\n","      x = self.pool(F.relu(self.conv3(x)))\n","      x = self.pool(F.relu(self.conv4(x)))\n","      x = F.relu(self.conv5(x))\n","      x = x.view(-1, 2888)\n","      x = F.relu(self.fc1(x))\n","      x = F.relu(self.fc2(x))\n","      x = self.fc3(x)\n","      return x \n","\n","model_ft = Model()\n","\n","model_ft = model_ft.to(device)"],"execution_count":88,"outputs":[]},{"cell_type":"code","metadata":{"id":"ei45AQERidLO","executionInfo":{"status":"ok","timestamp":1619050239408,"user_tz":240,"elapsed":289,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}}},"source":["def save_model(model, name):\n","  if (path.exists(name + \".pth\")): raise Exception(\"already exists\")\n","  else: save(model.state_dict(), name + \".pth\")\n"],"execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"id":"qeswSUNzl2Ab","executionInfo":{"status":"ok","timestamp":1619050240681,"user_tz":240,"elapsed":296,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}}},"source":["train_dataset = OurDataset(data_transforms=None,valid=False)\n","\n","trainloader = torch.utils.data.DataLoader(train_dataset, \n","                                          batch_size = args.batch_size, \n","                                          shuffle = True, \n","                                          num_workers = 2)\n","\n","valid_dataset = OurDataset(data_transforms=None,valid=True)\n","validloader = torch.utils.data.DataLoader(valid_dataset, \n","                                          batch_size = args.batch_size, \n","                                          shuffle = True, \n","                                          num_workers = 2)"],"execution_count":70,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ArFRQWF37VqL"},"source":["Train new model"]},{"cell_type":"code","metadata":{"id":"5fIreIej7YB5","executionInfo":{"status":"ok","timestamp":1619050713474,"user_tz":240,"elapsed":347,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}}},"source":["def train_model(args, model):\n","\n","\n","    model = model.to(device) \n","\n","    #transform = transforms.Compose([transforms.ToTensor(),\n","    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","   \n","    #train_dataset = OurDataset(data_transforms=transform)\n","    #valid_dataset = OurDataset(data_transforms=transform)\n","\n","    \n","    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    prev_val_acc = 0\n","    running_loss = 0.0\n","    best_val_acc = -1000\n","    for epoch in range(args.max_epochs):     # will get interupted by convergence test if validation acc drops\n","      for i, data in enumerate(trainloader, 0):\n","        # print(\"started i loop\", i)\n","        for j in range(3):\n","          img = data[0][j]\n","          # get the inputs; data is a list of [inputs, labels]\n","          inputs, labels = img.to(device), data[1].to(device)\n","          inputs = inputs.float()         # Broke our RAM (?)\n","\n","          # zero the parameter gradients\n","          optimizer.zero_grad()\n","\n","          # forward + backward + optimize\n","          outputs = model(inputs)\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          running_loss += loss.item()\n","          del inputs, labels, loss        # added to reduce RAM issues\n","          gc.collect()\n","\n","        # if i % 1000 == 999:    # print every 1000 mini-batches\n","        if i % 50 == 49:\n","            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 1000))\n","            running_loss = 0.0\n","\n","        # print(\"finished i loop\", i)\n","        # print()\n","\n","    save_model(model, \"/content/drive/Shareddrives/GeoTracking_AI/custom_attempt_skip2\")\n","\n","        \n","    print('Finished Training')"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"id":"vESdHoIt7Wzf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619051011940,"user_tz":240,"elapsed":274601,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}},"outputId":"3dd0a439-5010-4412-ecec-b5c61c05c886"},"source":["model_ft = train_model(args, model_ft)"],"execution_count":85,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"],"name":"stderr"},{"output_type":"stream","text":["[1,    50] loss: 0.131\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"],"name":"stderr"},{"output_type":"stream","text":["[2,    50] loss: 0.121\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"],"name":"stderr"},{"output_type":"stream","text":["[3,    50] loss: 0.111\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sVrLAxiJpa3I","executionInfo":{"status":"ok","timestamp":1619051019482,"user_tz":240,"elapsed":288,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}}},"source":["def accuracy_labels(preds, labels):\n","    return np.sum(preds == labels)/len(preds)"],"execution_count":86,"outputs":[]},{"cell_type":"code","metadata":{"id":"MXsb7oVg-qU_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619051027580,"user_tz":240,"elapsed":297,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}},"outputId":"e9992b45-426e-402b-9d7a-5308de13cfc3"},"source":["val_model = model_ft\n","val_dict = load(\"/content/drive/Shareddrives/GeoTracking_AI/custom_attempt_skip2.pth\")\n","val_model.load_state_dict(val_dict)"],"execution_count":89,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"code","metadata":{"id":"6mXAKcWcfbI2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619051038981,"user_tz":240,"elapsed":9545,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}},"outputId":"21e3102c-f377-4d40-a82e-bb0f3e8de739"},"source":["  # Test on Val set\n","  test_batch_size = 64\n","  out_preds = []\n","  out_labels = []\n","  for (X,Y) in validloader:\n","    X = X[0].to(device)\n","    Y = Y.to(device)\n","    X = X.float()         # Broke our RAM (working at 64, not 256)\n","    y_pred = torch.argmax(val_model(X), dim = 1).tolist()\n","    print(y_pred)\n","    y_pred = map(int, y_pred)\n","    print(y_pred)\n","    out_preds.extend(list(y_pred))\n","    out_labels.extend(Y.tolist())\n","      \n","  this_val_acc = accuracy_labels(np.array(out_preds), np.array(out_labels))\n","\n","  print('new_val_acc: %.3f'  %( this_val_acc))\n"],"execution_count":90,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"],"name":"stderr"},{"output_type":"stream","text":["[0, 4, 3, 7, 7, 0, 0, 0, 8, 0, 7, 8, 5, 0, 3, 8, 0, 3, 3, 3, 0, 0, 7, 7, 5, 7, 7, 3, 5, 5, 5, 0, 1, 5, 3, 5, 3, 7, 7, 5, 5, 5, 5, 7, 8, 3, 1, 3, 8, 3, 7, 0, 0, 0, 5, 7, 5, 5, 5, 5, 5, 0, 4, 1]\n","<map object at 0x7fc46b289050>\n","[7, 5, 3, 5, 0, 4, 3, 6, 5, 0, 5, 5, 0, 0, 1, 3, 0, 8, 1, 5, 8, 7, 7, 0, 6, 3, 8, 4, 5, 7, 0, 8, 5, 5, 0, 5, 5, 0, 0, 5, 3, 0, 3, 5, 5, 0, 3, 6, 1, 0, 7, 3, 1, 7, 0, 5, 7, 3, 8, 0, 5, 5, 3, 0]\n","<map object at 0x7fc4060786d0>\n","[0, 4, 7, 7, 5, 3, 1, 5, 0, 0, 5, 5, 0, 5, 5, 3, 8, 7, 3, 3, 0, 8, 5, 3, 0, 0, 1, 5, 0, 1, 4, 1, 0, 3, 8, 5, 5, 3, 1, 8, 5, 5, 6, 8, 5, 8, 7, 1, 6, 0, 4, 7, 0, 0, 0, 0, 8, 3, 7, 7, 0, 0, 0, 5]\n","<map object at 0x7fc46b289050>\n","[5, 3, 3, 3, 7, 5, 7, 7, 3, 3, 4, 6, 7, 1, 3, 3, 0, 8, 0, 0, 3, 3, 3, 0, 7, 6, 0, 3, 6, 7, 5, 1, 0, 5, 7, 6, 7, 7, 5, 7, 4, 7, 8, 8, 3, 4, 5, 8, 6, 3, 5, 3, 8, 3, 0, 5, 5, 3, 0, 1, 5, 0, 6, 8]\n","<map object at 0x7fc4060786d0>\n","[1, 3, 8, 0, 0, 8, 6, 1, 1, 0, 1, 1, 5, 7, 0, 3, 0, 0, 7, 1, 7, 7, 8, 7, 6, 3, 7, 5, 0, 5, 4, 5, 5, 0, 5, 7, 3, 5, 4, 7, 6, 3, 1, 1, 3, 4, 4, 5, 6, 5, 3, 5, 5, 7, 1, 5, 6, 3, 1, 3, 3, 3, 5, 0]\n","<map object at 0x7fc46b289050>\n","[1, 8, 6, 3, 7, 0, 4, 3, 0, 3, 6, 7, 7, 7, 8, 7, 1, 1, 1, 5, 7, 0, 1, 4, 5, 0, 3, 5, 3, 5, 7, 3, 0, 3, 1, 5, 3, 0, 3, 3, 0, 0, 0, 3, 0, 0, 0, 4, 3, 3, 8, 5, 6, 5, 7, 3, 0, 8, 0, 1, 6, 5, 1, 0]\n","<map object at 0x7fc400441b90>\n","[3, 3, 5, 1, 1, 8, 3, 0, 4, 7, 0, 5, 3, 4, 4, 1]\n","<map object at 0x7fc400441610>\n","new_val_acc: 0.512\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LyllUFNQBHpU"},"source":["Report:\n","\n","* Made our own dataset - DONE\n","\n","* Transfer Model - 4/15\n","  * Hyper-parameter testing\n","* Model from Scratch (do auto-tuning or hand-tune)\n","  * Hyper-parameter testing\n","* Have one of two models work well (compared to human benchmark)\n","\n","Write Report - 4/23-4/30\n","\n","* Visualization that we can see images, their correct labels, model's guess for label\n","* Percentage correct for each city bar graph"]}]}