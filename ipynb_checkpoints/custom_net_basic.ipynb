{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"custom_net.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"8PTqRjyk42Am"},"source":["Recreation of https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"]},{"cell_type":"code","metadata":{"id":"WTPDU6W34yze","executionInfo":{"status":"ok","timestamp":1618934323008,"user_tz":240,"elapsed":4739,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}}},"source":["import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torch import save\n","from torch import load\n","from os import path\n","\n","#import torch.utils.tensorboard as tb\n","\n","from PIL import Image\n","\n","from torchvision import datasets, models, transforms\n","from torch.utils.data import Dataset, DataLoader\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np \n","import random \n","import os, math\n","\n","import gc\n","\n","import pdb\n","from skimage import io \n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","# device = torch.device(\"cpu\")"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f2iSYk7bApXh"},"source":["Reproducibility"]},{"cell_type":"code","metadata":{"id":"P4ym2s_AAoyp","executionInfo":{"status":"ok","timestamp":1618934323009,"user_tz":240,"elapsed":4731,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}}},"source":["# Set manual seed.\n","def runRamdomSeed():\n","    torch.manual_seed(234)\n","    np.random.seed(234)\n","    random.seed(234)\n","    # Disabling the benchmarking feature with torch.backends.cudnn.benchmark = False \n","    # causes cuDNN to deterministically select an algorithm, possibly at the cost of reduced performance.\n","    torch.backends.cudnn.benchmark = False \n","\n","runRamdomSeed()"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JAltxzDh5DLG"},"source":["First we need to import our data."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YvMhA5-2AHLg","executionInfo":{"status":"ok","timestamp":1618934509607,"user_tz":240,"elapsed":191325,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}},"outputId":"f35e2df3-bb2a-47f2-d700-0b78becbdc73"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5ZBiWNaQD3S2"},"source":["Then we need to establish how we will transform the data to fit into NN"]},{"cell_type":"code","metadata":{"id":"iiRf9KiYD632","executionInfo":{"status":"ok","timestamp":1618934509609,"user_tz":240,"elapsed":191322,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}}},"source":["unused_data_transforms = transforms.Compose([\n","        # transforms.RandomResizedCrop(224),\n","        # transforms.RandomHorizontalFlip(),\n","        transforms.Resize(256),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        ])"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"SG8TTC9W5Bvf","executionInfo":{"status":"ok","timestamp":1618934509611,"user_tz":240,"elapsed":191321,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}}},"source":["\n","class OurDataset(Dataset):\n","    def __init__(self, data_transforms=None, valid=False):\n","        self.data_transforms = data_transforms\n","        if not valid:\n","          csv_path = \"/content/drive/Shareddrives/GeoTracking_AI/image_data.csv\"\n","          self.image_path = \"/content/drive/Shareddrives/GeoTracking_AI/images\"\n","        if valid:\n","          csv_path = \"/content/drive/Shareddrives/GeoTracking_AI/image_valid_data.csv\"\n","          self.image_path = \"/content/drive/Shareddrives/GeoTracking_AI/valid_images\"\n","        \n","        full_csv_frame = pd.read_csv(csv_path)\n","        csv_frame = full_csv_frame[[\"img_id\", \"city_id\", \"heading\"]]\n","        \n","        self.pd_frame = csv_frame\n","\n","        np_frame = csv_frame.to_numpy()\n","\n","        \n","\n","    def __len__(self):\n","        return self.pd_frame.iloc[:, 0].size\n","\n","\n","    def __getitem__(self, idx):\n","        image_path = self.image_path + \"/\" + str(self.pd_frame.iloc[idx, 0]).zfill(5) \n","        img1 = Image.open(image_path + \"_\" + str( (self.pd_frame.iloc[idx, 2]) ).zfill(3) + \".jpg\")\n","        img2 = Image.open(image_path + \"_\" + str( (self.pd_frame.iloc[idx, 2] + 120)%360 ).zfill(3) + \".jpg\")\n","        img3 = Image.open(image_path + \"_\" + str( (self.pd_frame.iloc[idx, 2] + 240)%360 ).zfill(3) + \".jpg\")\n","      \n","        img1 = torch.from_numpy(np.asarray(img1))     # convert to PyTorch Tensor\n","        img2 = torch.from_numpy(np.asarray(img2))  \n","        img3 = torch.from_numpy(np.asarray(img3)) \n","\n","\n","        if self.data_transforms != None:\n","          img1 = self.data_transforms(img1)\n","          img2 = self.data_transforms(img2)\n","          img3 = self.data_transforms(img3)\n","        else:\n","          # Change from 640, 640, 3 to 3, 640, 640\n","          img1 = np.asarray(img1).transpose(-1, 0, 1)\n","          img2 = np.asarray(img2).transpose(-1, 0, 1)\n","          img3 = np.asarray(img3).transpose(-1, 0, 1)\n","        \n","        # img1 = torch.from_numpy(np.asarray(img1))     # convert to PyTorch Tensor (covered in transforms?)\n","        # img2 = torch.from_numpy(np.asarray(img2))     \n","        # img3 = torch.from_numpy(np.asarray(img3))     \n","\n","\n","        return (img1, img2, img3) , self.pd_frame.iloc[idx, 1]\n"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"berUZDtM66Oi"},"source":["Set Arguments"]},{"cell_type":"code","metadata":{"id":"_1YRGXOe67mA","executionInfo":{"status":"ok","timestamp":1618940816885,"user_tz":240,"elapsed":414,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}}},"source":["class Args(object):\n","    pass\n","\n","args = Args();\n","\n","args.learning_rate = .001\n","args.max_epochs = 5\n","args.batch_size = 16\n"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vYdYL7CL49Wj"},"source":["Start by grabbing the already existing ResNet18 library"]},{"cell_type":"code","metadata":{"id":"vLB1ob5T5AKD","executionInfo":{"status":"ok","timestamp":1618941941649,"user_tz":240,"elapsed":717,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}}},"source":["class Model(nn.Module):\n","  def __init__(self):\n","      super(Model, self).__init__()\n","      self.conv1 = nn.Conv2d(3, 6, 5)\n","      self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","      self.conv2 = nn.Conv2d(6, 8, 5)\n","      self.conv3 = nn.Conv2d(8, 8, 5)\n","      self.conv4 = nn.Conv2d(8, 8, 5)\n","      self.conv5 = nn.Conv2d(8, 8, 5)\n","      #self.conv6 = nn.Conv2d(8, 8, 5)\n","      #self.conv7 = nn.Conv2d(8, 8, 5)\n","      #self.conv8 = nn.Conv2d(8, 8, 5)\n","      self.fc1 = nn.Linear(2048, 84)\n","      #self.fc2 = nn.Linear(120, 84)\n","      self.fc3 = nn.Linear(84, 10)            # Note that output has dimension 10\n","  \n","  def forward(self, x):\n","      x = self.pool(F.relu(self.conv1(x)))\n","      x = self.pool(F.relu(self.conv2(x)))\n","      x = self.pool(F.relu(self.conv3(x)))\n","      x = self.pool(F.relu(self.conv4(x)))\n","      x = self.pool(F.relu(self.conv5(x)))\n","      #x = self.pool(F.relu(self.conv6(x)))\n","      #x = self.pool(F.relu(self.conv7(x)))\n","      #x = self.pool(F.relu(self.conv8(x)))\n","      #print(x.shape)\n","      x = x.view(-1, 2048)\n","      x = F.relu(self.fc1(x))\n","      #x = F.relu(self.fc2(x))\n","      x = self.fc3(x)\n","      return x \n","\n","model_ft = Model()\n","\n","model_ft = model_ft.to(device)"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"ei45AQERidLO","executionInfo":{"status":"ok","timestamp":1618938992824,"user_tz":240,"elapsed":901,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}}},"source":["def save_model(model, name):\n","  if (path.exists(name + \".pth\")): raise Exception(\"already exists\")\n","  else: save(model.state_dict(), name + \".pth\")\n"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"qeswSUNzl2Ab","executionInfo":{"status":"ok","timestamp":1618938995478,"user_tz":240,"elapsed":883,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}}},"source":["train_dataset = OurDataset(data_transforms=None,valid=False)\n","\n","trainloader = torch.utils.data.DataLoader(train_dataset, \n","                                          batch_size = args.batch_size, \n","                                          shuffle = True, \n","                                          num_workers = 2)\n","\n","valid_dataset = OurDataset(data_transforms=None,valid=True)\n","validloader = torch.utils.data.DataLoader(valid_dataset, \n","                                          batch_size = args.batch_size, \n","                                          shuffle = True, \n","                                          num_workers = 2)"],"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ArFRQWF37VqL"},"source":["Train new model"]},{"cell_type":"code","metadata":{"id":"5fIreIej7YB5","executionInfo":{"status":"ok","timestamp":1618940654847,"user_tz":240,"elapsed":454,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}}},"source":["def train_model(args, model):\n","\n","\n","    model = model.to(device) \n","\n","    #transform = transforms.Compose([transforms.ToTensor(),\n","    #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","   \n","    #train_dataset = OurDataset(data_transforms=transform)\n","    #valid_dataset = OurDataset(data_transforms=transform)\n","\n","    \n","    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    prev_val_acc = 0\n","    running_loss = 0.0\n","    best_val_acc = -1000\n","    for epoch in range(args.max_epochs):     # will get interupted by convergence test if validation acc drops\n","      for i, data in enumerate(trainloader, 0):\n","        # print(\"started i loop\", i)\n","        for j in range(3):\n","          img = data[0][j]\n","          # get the inputs; data is a list of [inputs, labels]\n","          inputs, labels = img.to(device), data[1].to(device)\n","          inputs = inputs.float()         # Broke our RAM (?)\n","\n","          # zero the parameter gradients\n","          optimizer.zero_grad()\n","\n","          # forward + backward + optimize\n","          outputs = model(inputs)\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          running_loss += loss.item()\n","          del inputs, labels, loss        # added to reduce RAM issues\n","          gc.collect()\n","\n","        # if i % 1000 == 999:    # print every 1000 mini-batches\n","        if i % 50 == 49:\n","            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 1000))\n","            running_loss = 0.0\n","\n","        # print(\"finished i loop\", i)\n","        # print()\n","\n","    save_model(model, \"/content/drive/Shareddrives/GeoTracking_AI/custom_attempt0\")\n","\n","        \n","    print('Finished Training')"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"vESdHoIt7Wzf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618941839808,"user_tz":240,"elapsed":1018971,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}},"outputId":"280b4b88-eedc-407c-ebb9-76cea529a909"},"source":["model_ft = train_model(args, model_ft)"],"execution_count":45,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"],"name":"stderr"},{"output_type":"stream","text":["[1,    50] loss: 0.148\n","[1,   100] loss: 0.143\n","[1,   150] loss: 0.148\n","[1,   200] loss: 0.147\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"],"name":"stderr"},{"output_type":"stream","text":["[2,    50] loss: 0.122\n","[2,   100] loss: 0.130\n","[2,   150] loss: 0.136\n","[2,   200] loss: 0.138\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"],"name":"stderr"},{"output_type":"stream","text":["[3,    50] loss: 0.109\n","[3,   100] loss: 0.125\n","[3,   150] loss: 0.123\n","[3,   200] loss: 0.118\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"],"name":"stderr"},{"output_type":"stream","text":["[4,    50] loss: 0.098\n","[4,   100] loss: 0.094\n","[4,   150] loss: 0.105\n","[4,   200] loss: 0.114\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"],"name":"stderr"},{"output_type":"stream","text":["[5,    50] loss: 0.081\n","[5,   100] loss: 0.085\n","[5,   150] loss: 0.091\n","[5,   200] loss: 0.104\n","Finished Training\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sVrLAxiJpa3I","executionInfo":{"status":"ok","timestamp":1618941949752,"user_tz":240,"elapsed":700,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}}},"source":["def accuracy_labels(preds, labels):\n","    return np.sum(preds == labels)/len(preds)"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"MXsb7oVg-qU_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618941951838,"user_tz":240,"elapsed":850,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}},"outputId":"213ab0c8-2f20-46d0-fc5b-ccf2535bf93d"},"source":["val_model = model_ft\n","val_dict = load(\"/content/drive/Shareddrives/GeoTracking_AI/custom_attempt0.pth\")\n","val_model.load_state_dict(val_dict)"],"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"6mXAKcWcfbI2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618942241472,"user_tz":240,"elapsed":286061,"user":{"displayName":"Zohar Singer","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingIjdEVNv4mPnseFJITIbZFpDGWUrDatCWkm0=s64","userId":"15595248181255472097"}},"outputId":"16f98227-d4fb-46f1-f237-1c089b11d172"},"source":["  # Test on Val set\n","  test_batch_size = 64\n","  out_preds = []\n","  out_labels = []\n","  for (X,Y) in validloader:\n","    X = X[0].to(device)\n","    Y = Y.to(device)\n","    X = X.float()         # Broke our RAM (working at 64, not 256)\n","    y_pred = torch.argmax(val_model(X), dim = 1).tolist()\n","    print(y_pred)\n","    y_pred = map(int, y_pred)\n","    print(y_pred)\n","    out_preds.extend(list(y_pred))\n","    out_labels.extend(Y.tolist())\n","      \n","  this_val_acc = accuracy_labels(np.array(out_preds), np.array(out_labels))\n","\n","  print('new_val_acc: %.3f'  %( this_val_acc))\n"],"execution_count":54,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n"],"name":"stderr"},{"output_type":"stream","text":["[8, 0, 0, 0, 3, 5, 0, 8, 6, 6, 0, 5, 8, 0, 4, 8]\n","<map object at 0x7f1fbbdc8510>\n","[7, 0, 5, 3, 6, 7, 0, 4, 0, 0, 7, 0, 4, 8, 0, 3]\n","<map object at 0x7f1fbce08c90>\n","[4, 8, 1, 7, 5, 7, 5, 8, 5, 0, 8, 5, 0, 1, 8, 4]\n","<map object at 0x7f1fbbdc88d0>\n","[7, 8, 5, 4, 8, 3, 3, 6, 8, 0, 3, 5, 4, 5, 8, 7]\n","<map object at 0x7f1fbbdc8510>\n","[4, 5, 8, 6, 0, 5, 5, 4, 4, 5, 5, 3, 6, 6, 3, 0]\n","<map object at 0x7f1fbbdacdd0>\n","[8, 3, 4, 1, 6, 8, 3, 8, 5, 6, 1, 8, 8, 5, 1, 0]\n","<map object at 0x7f1fbbdbaf50>\n","[3, 8, 7, 4, 5, 0, 5, 0, 0, 0, 0, 5, 0, 4, 7, 0]\n","<map object at 0x7f1fbce0bf50>\n","[8, 7, 5, 7, 8, 7, 4, 1, 4, 4, 6, 8, 4, 6, 8, 7]\n","<map object at 0x7f1fbce0bf50>\n","[3, 4, 5, 0, 8, 6, 5, 6, 8, 3, 5, 1, 7, 4, 4, 4]\n","<map object at 0x7f1fbce17c10>\n","[3, 3, 6, 6, 3, 5, 3, 0, 6, 5, 6, 6, 8, 6, 4, 4]\n","<map object at 0x7f1fbce17e90>\n","[5, 4, 8, 0, 8, 1, 4, 3, 0, 7, 8, 4, 6, 1, 0, 5]\n","<map object at 0x7f1fbbdfb990>\n","[6, 8, 1, 6, 5, 7, 7, 8, 4, 7, 8, 4, 7, 7, 5, 3]\n","<map object at 0x7f1fb9a93ed0>\n","[5, 3, 0, 8, 4, 0, 8, 0, 0, 3, 7, 7, 1, 0, 7, 4]\n","<map object at 0x7f1fbce08c90>\n","[6, 0, 8, 8, 0, 4, 4, 0, 7, 1, 7, 5, 8, 4, 0, 7]\n","<map object at 0x7f1fb99d30d0>\n","[7, 3, 5, 0, 0, 7, 4, 8, 8, 4, 0, 3, 5, 0, 7, 5]\n","<map object at 0x7f1fbbdfb990>\n","[6, 5, 6, 8, 7, 8, 7, 8, 8, 6, 5, 3, 7, 8, 6, 7]\n","<map object at 0x7f1fbb9da890>\n","[5, 4, 1, 6, 8, 5, 8, 8, 1, 4, 5, 6, 3, 3, 5, 1]\n","<map object at 0x7f1fbbdfb990>\n","[6, 5, 1, 7, 0, 3, 4, 6, 8, 0, 0, 5, 7, 0, 5, 8]\n","<map object at 0x7f1fb26e3b90>\n","[5, 8, 5, 7, 7, 5, 7, 6, 8, 7, 4, 7, 4, 8, 7, 4]\n","<map object at 0x7f1fb270e910>\n","[6, 5, 4, 7, 8, 1, 0, 1, 1, 7, 5, 6, 5, 6, 8, 6]\n","<map object at 0x7f1fbd746d50>\n","[1, 8, 5, 3, 6, 0, 1, 7, 4, 1, 1, 6, 6, 4, 5, 5]\n","<map object at 0x7f1fbce0ca10>\n","[1, 4, 3, 4, 5, 7, 3, 5, 8, 8, 1, 3, 7, 0, 7, 6]\n","<map object at 0x7f1fb99f0c50>\n","[3, 6, 6, 5, 7, 3, 5, 3, 6, 3, 0, 5, 7, 1, 1, 5]\n","<map object at 0x7f1fbce17390>\n","[0, 6, 5, 6, 1, 6, 7, 3, 0, 4, 3, 5, 3, 7, 5, 0]\n","<map object at 0x7f1fb276cc50>\n","[4, 6, 4, 5, 6, 5, 8, 3, 8, 4, 6, 6, 4, 1, 5, 6]\n","<map object at 0x7f1fbbdb7bd0>\n","new_val_acc: 0.480\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LyllUFNQBHpU"},"source":["Report:\n","\n","* Made our own dataset - DONE\n","\n","* Transfer Model - 4/15\n","  * Hyper-parameter testing\n","* Model from Scratch (do auto-tuning or hand-tune)\n","  * Hyper-parameter testing\n","* Have one of two models work well (compared to human benchmark)\n","\n","Write Report - 4/23-4/30\n","\n","* Visualization that we can see images, their correct labels, model's guess for label\n","* Percentage correct for each city bar graph"]}]}